{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"cpiVAE: Cross-platform Proteomics Imputation using Variational Autoencoders","text":"<p>Welcome to the comprehensive documentation for cpiVAE, a highly customizable and user friendly framework for cross-platform proteomics data imputation using Variational Autoencoders.</p>"},{"location":"#overview","title":"Overview","text":"<p>cpiVAE addresses the critical challenge of data harmonization in proteomics research by enabling accurate imputation between different measurement platforms (e.g., Olink and SomaScan). Our approach leverages deep generative models to learn shared latent representations that capture the underlying biological signals across platforms.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multi-Architecture Support: Joint VAE, VampPrior, IWAE, VQ-VAE, and easy addition of custom models</li> <li>Robust Baseline Methods: KNN and WNN implementations for comparison</li> <li>Comprehensive Evaluation: Feature importance analysis and quality control metrics</li> <li>Production Ready: PyTorch Lightning framework with full experiment tracking</li> <li>Flexible Configuration: YAML-based configuration setup for easy customization</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get started with cpiVAE in three simple steps:</p> <ol> <li> <p>Install Dependencies <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> <li> <p>Train a Model <pre><code>python scripts/train.py --config configs/default.yaml \\\n    --platform_a data/olink_train.csv \\\n    --platform_b data/somascan_train.csv\n</code></pre></p> </li> <li> <p>Perform Cross-Platform Imputation <pre><code>python scripts/impute.py --checkpoint outputs/model.ckpt \\\n    --platform_impute data/test.csv --impute_target b\n</code></pre></p> </li> </ol>"},{"location":"#documentation-sections","title":"Documentation Sections","text":"Section Description Training Model training with PyTorch Lightning Baselines KNN and WNN baseline implementations Imputation Cross-platform imputation pipeline Model Tuning Hyperparameter optimization and model selection Quality Control Data validation and preprocessing Feature Importance Analyzing learned representations Latent Space Visualization and interpretation Confidence &amp; Analysis Confidence estimation and downstream analysis Phenotype Association Discovery and targeted phenotype associations Comparison Benchmarking against baselines"},{"location":"#architecture","title":"Architecture","text":"<p>cpiVAE employs a dual-encoder, dual-decoder architecture that learns platform-specific representations while maintaining a shared latent space. This design enables:</p> <ul> <li>Bidirectional Imputation: A\u2192B and B\u2192A cross-platform prediction</li> <li>Latent Alignment: Shared biological signal representation</li> <li>Platform Adaptation: Handling platform-specific measurement characteristics</li> </ul>"},{"location":"#research-applications","title":"Research Applications","text":"<ul> <li>Multi-platform Studies: Harmonize data across different proteomics platforms</li> <li>Data Integration: Combine measurements from multiple cohorts or studies  </li> <li>Method Validation: Compare measurement consistency across platforms</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you use cpiVAE in your research, please cite:</p> <pre><code>TBD\n</code></pre>"},{"location":"baselines/","title":"Baseline Methods","text":""},{"location":"baselines/#overview","title":"Overview","text":"<p>The cpiVAE framework includes implementations of established baseline methods for cross-platform proteomics imputation. These methods serve as benchmarks for evaluating the performance of the cpiVAE model and provide alternative approaches for cross-platform data harmonization.</p>"},{"location":"baselines/#k-nearest-neighbors-knn-baseline","title":"K-Nearest Neighbors (KNN) Baseline","text":""},{"location":"baselines/#script-run_knn_comparisonpy","title":"Script: <code>run_knn_comparison.py</code>","text":"<p>Implements K-nearest neighbors regression for cross-platform imputation with comprehensive parameter optimization.</p>"},{"location":"baselines/#usage","title":"Usage","text":"<pre><code>python scripts/run_knn_comparison.py --platform_a PLATFORM_A_FILE --platform_b PLATFORM_B_FILE [OPTIONS]\n</code></pre>"},{"location":"baselines/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>--platform_a</code>, <code>--platform_b</code>: Training data files for both platforms</li> <li><code>--platform_impute</code>: Test data file for cross-platform imputation</li> <li><code>--impute_target</code>: Target platform (<code>a</code> or <code>b</code>)</li> <li><code>--k_values</code>: List of k values to test (default: [3,5,7,10,15,30,50,100,200])</li> <li><code>--kernel</code>: Weighting function (<code>uniform</code>, <code>distance</code>, <code>gaussian</code>, <code>exponential</code>, <code>tricube</code>)</li> <li><code>--cv_folds</code>: Cross-validation folds for parameter optimization</li> </ul>"},{"location":"baselines/#details","title":"Details","text":"<ol> <li>Data Preprocessing: Optional log transformation and standardization</li> <li>Parameter Search: Grid search over k values and kernel functions</li> <li>Cross-Validation: k-fold CV for robust parameter selection</li> <li>Imputation: Weighted average of k nearest neighbors in the source platform</li> <li>Kernel Functions: Multiple weighting schemes including Gaussian and polynomial</li> </ol>"},{"location":"baselines/#example","title":"Example","text":"<pre><code>python scripts/run_knn_comparison.py \\\n    --platform_a data/olink_overlap_train.csv \\\n    --platform_b data/somascan_overlap_train.csv \\\n    --platform_impute data/olink_overlap_test.csv \\\n    --impute_target b \\\n    --kernel gaussian \\\n    --output_dir outputs_knn\n</code></pre>"},{"location":"baselines/#weighted-nearest-neighbors-wnn-baseline","title":"Weighted Nearest Neighbors (WNN) Baseline","text":""},{"location":"baselines/#script-wnn_baselinepy","title":"Script: <code>wnn_baseline.py</code>","text":"<p>Implements the Weighted Nearest Neighbors algorithm adapted from Hao et al. (2021), originally developed for single-cell multimodal data integration.</p>"},{"location":"baselines/#usage_1","title":"Usage","text":"<pre><code>python scripts/wnn_baseline.py --platform_a PLATFORM_A_FILE --platform_b PLATFORM_B_FILE [OPTIONS]\n</code></pre>"},{"location":"baselines/#key-parameters_1","title":"Key Parameters","text":"<ul> <li><code>--platform_a</code>, <code>--platform_b</code>: Training data files</li> <li><code>--platform_impute</code>: Test data for imputation</li> <li><code>--impute_target</code>: Target platform for imputation</li> <li><code>--n_neighbors</code>: Number of neighbors for graph construction (default: 20)</li> <li><code>--n_components</code>: PCA components for dimensionality reduction (default: 50)</li> <li><code>--sigma</code>: Bandwidth parameter for weight computation (default: 1.0)</li> </ul>"},{"location":"baselines/#example_1","title":"Example","text":"<pre><code># WNN imputation from SomaScan to Olink\npython scripts/wnn_baseline.py \\\n    --platform_a data/olink_overlap_train.csv \\\n    --platform_b data/somascan_overlap_train.csv \\\n    --platform_impute data/somascan_overlap_test.csv \\\n    --impute_target a \\\n    --output_dir outputs_wnn\n</code></pre>"},{"location":"comparison/","title":"Results Comparison and Analysis (<code>compare_result.py</code>)","text":""},{"location":"comparison/#overview","title":"Overview","text":"<p>The <code>compare_result.py</code> script provides a comprehensive framework for evaluating and comparing cross-platform proteomics imputation methods. It generates figures, statistical analyses, and detailed performance metrics.</p>"},{"location":"comparison/#usage","title":"Usage","text":"<pre><code>python scripts/compare_result.py --truth_a TRUTH_A --truth_b TRUTH_B --imp_a_m1 IMP_A_M1 --imp_b_m1 IMP_B_M1 [OPTIONS]\n</code></pre>"},{"location":"comparison/#required-arguments","title":"Required Arguments","text":"<ul> <li><code>--truth_a</code>: Ground truth data for platform A (CSV/TXT)</li> <li><code>--truth_b</code>: Ground truth data for platform B (CSV/TXT)</li> <li><code>--imp_a_m1</code>: Method 1 imputed data for platform A</li> <li><code>--imp_b_m1</code>: Method 1 imputed data for platform B</li> </ul>"},{"location":"comparison/#optional-method-comparisons","title":"Optional Method Comparisons","text":"<ul> <li><code>--imp_a_m2</code>, <code>--imp_b_m2</code>: Method 2 imputed data</li> <li><code>--imp_a_m3</code>, <code>--imp_b_m3</code>: Method 3 imputed data  </li> <li><code>--imp_a_m4</code>, <code>--imp_b_m4</code>: Method 4 imputed data</li> <li><code>--method1_name</code>, <code>--method2_name</code>, etc.: Names for methods in plots</li> </ul>"},{"location":"comparison/#platform-and-network-options","title":"Platform and Network Options","text":"<ul> <li><code>--platform_a_name</code>, <code>--platform_b_name</code>: Platform names for labels</li> <li><code>--ppi_file</code>: Protein-protein interaction network file</li> <li><code>--gri_file</code>: Gene regulatory interaction network file</li> <li><code>--transpose</code>: Transpose data if samples are in rows</li> </ul>"},{"location":"comparison/#output-and-display-options","title":"Output and Display Options","text":"<ul> <li><code>--output_dir</code>: Output directory for results (default: <code>outputs_comparison</code>)</li> <li><code>--figsize</code>: Figure dimensions as \"width,height\" (default: \"12,10\")</li> <li><code>--dpi</code>: Figure resolution (default: 300)</li> <li><code>--save_data</code>: Save processed data matrices</li> </ul>"},{"location":"comparison/#analysis","title":"Analysis","text":""},{"location":"comparison/#1-overall-performance-analysis","title":"1. Overall Performance Analysis","text":"<p>Metrics Computed: - R\u00b2 Score: Coefficient of determination - Pearson Correlation: Linear correlation coefficient - Spearman Correlation: Rank-based correlation - RMSE: Root mean squared error - MAE: Mean absolute error</p>"},{"location":"comparison/#2-feature-wise-analysis","title":"2. Feature-wise Analysis","text":"<p>Per-protein/analyte evaluation: - Individual feature correlation distributions - Feature-wise R\u00b2 score comparisons - Identification of challenging vs. well-imputed features</p> <p>Outputs: - <code>feature_metrics.csv</code>: Per-feature performance statistics - Feature correlation heatmaps - Distribution plots of feature-wise correlations</p>"},{"location":"comparison/#3-sample-wise-analysis","title":"3. Sample-wise Analysis","text":"<p>Per-sample evaluation: - Sample-wise correlation across methods - Identification of outlier samples - Sample quality assessment - Correlation with sample metadata (if provided)</p> <p>Outputs: - <code>sample_metrics.csv</code>: Per-sample performance statistics - Sample correlation scatter plots - Sample quality rankings</p>"},{"location":"comparison/#4-cross-platform-concordance","title":"4. Cross-platform Concordance","text":"<p>Between-platform consistency: - Platform A vs Platform B correlation in latent space - Cross-platform feature relationships - Platform-specific bias detection</p>"},{"location":"comparison/#5-distribution-preservation","title":"5. Distribution Preservation","text":"<p>Data distribution analysis: - Value range preservation - Distribution shape comparison (KS tests) - Outlier detection and handling - Log-transformation effects</p>"},{"location":"comparison/#6-dimensionality-reduction-analysis","title":"6. Dimensionality Reduction Analysis","text":"<p>Low-dimensional visualization: - PCA: Principal component analysis - UMAP: Uniform manifold approximation - Cluster separation analysis</p>"},{"location":"comparison/#7-network-based-biological-validation","title":"7. Network-based Biological Validation","text":"<p>When PPI/GRI files provided: - Protein interaction network analysis - Gene regulatory network validation - Functional enrichment analysis - Network topology preservation</p>"},{"location":"comparison/#statistical-testing","title":"Statistical Testing","text":""},{"location":"comparison/#significance-tests","title":"Significance Tests","text":"<ol> <li>Paired t-tests: Between methods on same samples</li> <li>Wilcoxon signed-rank: Non-parametric method comparison</li> <li>Kolmogorov-Smirnov: Distribution shape comparison</li> <li>Chi-square: Categorical association testing</li> <li>ANOVA: Multi-method performance comparison</li> </ol>"},{"location":"comparison/#multiple-testing-correction","title":"Multiple Testing Correction","text":"<ul> <li>Bonferroni correction: Conservative correction for multiple comparisons</li> <li>False Discovery Rate (FDR): Benjamini-Hochberg procedure</li> <li>Family-wise Error Rate (FWER): Holm-Bonferroni method</li> </ul>"},{"location":"comparison/#effect-size-reporting","title":"Effect Size Reporting","text":"<ul> <li>Cohen's d: Standardized mean difference</li> <li>Eta-squared: Proportion of variance explained</li> <li>Confidence intervals: 95% CI for all major metrics</li> </ul>"},{"location":"comparison/#examples","title":"Examples","text":""},{"location":"comparison/#four-method-comparison","title":"Four-Method Comparison","text":"<pre><code>python scripts/compare_result.py \\\n    --truth_a data/olink_overlap_test.csv \\\n    --truth_b data/somascan_overlap_test.csv \\\n    --imp_a_m1 data/olink_overlap_test_imputed_vae.csv \\\n    --imp_a_m2 data/olink_overlap_test_imputed_wnn.csv \\\n    --imp_a_m3 data/olink_overlap_test_imputed_knn.csv \\\n    --imp_a_m4 data/olink_overlap_test_imputed_vae_shuffled.csv \\\n    --imp_b_m1 data/somascan_overlap_test_imputed_vae.csv \\\n    --imp_b_m2 data/somascan_overlap_test_imputed_wnn.csv \\\n    --imp_b_m3 data/somascan_overlap_test_imputed_knn.csv \\\n    --imp_b_m4 data/somascan_overlap_test_imputed_vae_shuffled.csv \\\n    --method1_name \"jointVAE\" \\\n    --method2_name \"WNN\" \\\n    --method3_name \"KNN\" \\\n    --method4_name \"Permuted Control\" \\\n    --platform_a_name \"Olink\" \\\n    --platform_b_name \"SomaScan\" \\\n    --ppi_file data/human_annotated_PPIs.txt \\\n    --gri_file data/trrust.human.txt \\\n    --transpose \\\n    --output_dir outputs_comprehensive_comparison\n</code></pre>"},{"location":"confidence/","title":"Confidence &amp; Analysis (confidence.py, confidence_analysis.py)","text":""},{"location":"confidence/#overview","title":"Overview","text":"<p>This page covers both generating confidence (uncertainty) and analyzing how confidence relates to imputation performance.</p>"},{"location":"confidence/#part-i-confidence-estimation-confidencepy","title":"Part I \u2014 Confidence Estimation (<code>confidence.py</code>)","text":"<p><code>confidence.py</code> estimates per-cell uncertainty/confidence for cross-platform imputation with trained cpiVAE models. It reuses the same preprocessing and model-loading pipeline as <code>impute.py</code> and supports three methods:</p> <ul> <li>mc (Monte Carlo, default): Run K stochastic imputations and convert the coefficient of variation (CV) into a confidence score.</li> <li>delta: Single-pass analytical variance propagation from latent space through the decoder (delta method), optionally scaling to original feature space.</li> <li>latent: Directly export the encoder\u2019s latent variance per sample (no propagation).</li> </ul> <p>Interpretation: - mc: Higher score means higher confidence (confidence = 1 / (1 + CV)). - delta: Outputs variance in the target feature space. Higher variance indicates lower confidence. - latent: Outputs variance in the latent space per sample; useful as an intrinsic uncertainty signal.</p>"},{"location":"confidence/#usage","title":"Usage","text":"<pre><code>python scripts/confidence.py \\\n  --experiment_dir EXPERIMENT_DIR \\\n  --input_data INPUT_FILE \\\n  --source_platform {a,b} --target_platform {a,b} \\\n  --output OUTPUT_FILE [OPTIONS]\n</code></pre>"},{"location":"confidence/#required-arguments","title":"Required Arguments","text":"<ul> <li><code>--experiment_dir</code>: Path to experiment directory with checkpoint and preprocessing artifacts</li> <li><code>--input_data</code>: Input CSV/TXT (first column sample IDs, remaining columns features)</li> <li><code>--source_platform</code>: <code>a</code> or <code>b</code></li> <li><code>--target_platform</code>: <code>a</code> or <code>b</code> (must differ from source)</li> <li><code>--output</code>: Output CSV path</li> </ul>"},{"location":"confidence/#method-selection","title":"Method Selection","text":"<ul> <li><code>--method {mc,delta,latent}</code> (default: mc)</li> <li><code>mc</code>: K runs \u2192 CV \u2192 confidence score (1/(1+CV)) in original target scale</li> <li><code>delta</code>: Variance via Jacobian-based delta method in target scale</li> <li><code>latent</code>: Latent variance per sample (no propagation)</li> </ul>"},{"location":"confidence/#mc-options","title":"MC Options","text":"<ul> <li><code>--n_runs</code>: Number of stochastic imputations (default: 5). Larger values yield more stable CV estimates.</li> </ul>"},{"location":"confidence/#delta-options","title":"Delta Options","text":"<ul> <li><code>--delta_backend {hutchinson,exact}</code> (default: <code>hutchinson</code>)</li> <li><code>hutchinson</code>: Fast estimator of diag(J \u03a3 J^T) using jvp/vjp, scalable to large output dims</li> <li><code>exact</code>: Full Jacobian per sample (very slow; use only for small tests)</li> <li><code>--delta_probes</code>: Number of probe vectors for Hutchinson estimator (default: 16). Increase for smoother estimates.</li> </ul> <p>Notes: - The script attempts to map propagated variance back to original target feature scale if the saved scaler exposes <code>scale_</code> (std); variance scales with std^2. - All inputs are assumed to be in log space already for this project; we do not add extra log-domain adjustments.</p>"},{"location":"confidence/#output-format","title":"Output Format","text":"<ul> <li><code>mc</code> (confidence score): CSV with shape (n_samples \u00d7 n_target_features)</li> <li>Columns: target features (or generated names)</li> <li>Values in (0, 1]; higher is more confident</li> <li><code>delta</code> (variance): CSV with shape (n_samples \u00d7 n_target_features)</li> <li>Columns: target features (or generated names)</li> <li>Values: estimated output variance; higher means less confident</li> <li><code>latent</code> (variance): CSV with shape (n_samples \u00d7 latent_dim)</li> <li>Columns: <code>latent_var_dim_1</code>, <code>latent_var_dim_2</code>, ...</li> <li>Values: exp(logvar); higher means less confident</li> </ul> <p>All outputs include the sample ID column as the first column.</p>"},{"location":"confidence/#examples","title":"Examples","text":""},{"location":"confidence/#monte-carlo-confidence-olink-somascan","title":"Monte Carlo Confidence (Olink \u2192 SomaScan)","text":"<pre><code>python scripts/confidence.py \\\n  --experiment_dir outputs_vae/joint_vae_experiment/version_20250807-225313 \\\n  --input_data data/olink_overlap_test.csv \\\n  --source_platform a --target_platform b \\\n  --output data/confidence_mc_a2b.csv \\\n  --method mc --n_runs 20\n</code></pre>"},{"location":"confidence/#delta-fast-hutchinson","title":"Delta (Fast Hutchinson)","text":"<pre><code>python scripts/confidence.py \\\n  --experiment_dir outputs_vae/joint_vae_experiment/version_20250807-225313 \\\n  --input_data data/olink_overlap_test.csv \\\n  --source_platform a --target_platform b \\\n  --output data/confidence_delta_a2b.csv \\\n  --method delta --delta_backend hutchinson --delta_probes 16\n</code></pre>"},{"location":"confidence/#latent-variance","title":"Latent Variance","text":"<pre><code>python scripts/confidence.py \\\n  --experiment_dir outputs_vae/joint_vae_experiment/version_20250807-225313 \\\n  --input_data data/olink_overlap_test.csv \\\n  --source_platform a --target_platform b \\\n  --output data/confidence_latent_a2b.csv \\\n  --method latent\n</code></pre>"},{"location":"confidence/#performance-tips","title":"Performance Tips","text":"<ul> <li>Prefer <code>delta_backend=hutchinson</code> for large models/feature sets; the exact Jacobian backend is O(output_dim \u00d7 latent_dim) per sample.</li> <li>Increase <code>--delta_probes</code> to reduce estimator noise; decrease for speed.</li> <li>For <code>mc</code>, balance <code>--n_runs</code> with runtime; 10\u201320 is often sufficient.</li> </ul>"},{"location":"confidence/#interpretation","title":"Interpretation","text":"<ul> <li>Use <code>mc</code> confidence when you want a bounded score (0\u20131) that inversely reflects output variability.</li> <li>Use <code>delta</code> when you need an analytical, single-pass variance in the target feature space.</li> <li>Use <code>latent</code> for a quick, model-intrinsic uncertainty signal independent of the decoder.</li> </ul>"},{"location":"confidence/#part-ii-confidence-analysis-confidence_analysispy-confidence_analysis_oneplatformpy","title":"Part II \u2014 Confidence Analysis (<code>confidence_analysis.py</code> / <code>confidence_analysis_oneplatform.py</code>)","text":"<p>Analyze how confidence relates to performance by comparing confidence matrices against ground-truth and imputed matrices.</p>"},{"location":"confidence/#modes","title":"Modes","text":"<ul> <li>Single platform: use <code>confidence_analysis_oneplatform.py</code></li> <li>Two platforms: use <code>confidence_analysis.py</code> (plots split into two subplots, each with its own colorbar)</li> </ul>"},{"location":"confidence/#inputs","title":"Inputs","text":"<p>Single platform: - <code>--truth</code>: Ground truth matrix (features \u00d7 samples) - <code>--imputed</code>: Imputed matrix (samples \u00d7 features) - <code>--confidence</code>: Confidence matrix (samples \u00d7 features) - <code>--platform_name</code>: Name used in figures</p> <p>Two platforms additionally accept: - <code>--truth_a</code>, <code>--truth_b</code> - <code>--imputed_a</code>, <code>--imputed_b</code> - <code>--confidence_a</code>, <code>--confidence_b</code> - <code>--platform_a_name</code>, <code>--platform_b_name</code></p> <p>Common options: - <code>--correlation {pearson,spearman}</code> (default: pearson) - <code>--output_dir</code> for figures and tables - <code>--max_points</code> to downsample cell-wise scatter (default: 50,000)</p>"},{"location":"confidence/#what-it-computes","title":"What It Computes","text":"<ul> <li>Feature-wise: r between truth and imputed per feature; plot mean confidence (X) vs r (Y)</li> <li>Sample-wise: r per sample; plot mean confidence (X) vs r (Y)</li> <li>Cell-wise: confidence (X, log) vs |truth \u2212 imputed| (Y, log), with regression line</li> </ul> <p>Aggregation: uses mean confidence for feature-wise and sample-wise.</p> <p>Coloring: - Feature-wise: colored by mean feature value - Sample-wise: colored by mean sample value - Cell-wise: colored by mean feature value; each subplot has its own colorbar; subplots are square</p>"},{"location":"confidence/#outputs","title":"Outputs","text":"<p>Tables under <code>output_dir/data</code>: - <code>feature_confidence_vs_r.csv</code>, <code>sample_confidence_vs_r.csv</code> - optional downsample previews for cell-wise scatter</p> <p>Figures under <code>output_dir/figures</code>: - Single platform: <code>confidence_vs_r_featurewise.(pdf|png)</code>, <code>confidence_vs_r_samplewise.(pdf|png)</code>, <code>confidence_vs_abs_error_cells.(pdf|png)</code> - Two platforms: <code>*_split.(pdf|png)</code> variants for feature-wise, sample-wise, and cell-wise</p>"},{"location":"confidence/#examples_1","title":"Examples","text":"<p>Single platform: <pre><code>python scripts/confidence_analysis_oneplatform.py \\\n  --truth data/truth_platform_b.csv \\\n  --imputed outputs_vae/.../imputed_a2b.csv \\\n  --confidence outputs_vae/.../confidence_a2b.csv \\\n  --platform_name \"Platform B\" \\\n  --output_dir outputs_vae/confidence_analysis_b \\\n  --correlation pearson\n</code></pre></p> <p>Two platforms: <pre><code>python scripts/confidence_analysis.py \\\n  --truth_a data/truth_platform_a.csv --truth_b data/truth_platform_b.csv \\\n  --imputed_a outputs_vae/.../imputed_a.csv --imputed_b outputs_vae/.../imputed_b.csv \\\n  --confidence_a outputs_vae/.../confidence_a.csv --confidence_b outputs_vae/.../confidence_b.csv \\\n  --platform_a_name \"Platform A\" --platform_b_name \"Platform B\" \\\n  --output_dir outputs_vae/confidence_analysis_both \\\n  --correlation pearson\n</code></pre></p>"},{"location":"confidence/#notes-tips","title":"Notes &amp; Tips","text":"<ul> <li>Axes: confidence (X) and r (Y) for feature/sample-wise; log-log for cell-wise abs error</li> <li>The scripts auto-orient/align matrices by overlapping samples and features</li> <li>Use <code>--max_points</code> to keep cell-wise scatter fast on large datasets</li> </ul>"},{"location":"feature_importance/","title":"Feature Importance Analysis","text":"<p>The <code>feature_importance_analysis.py</code> script provides comprehensive analysis of feature importance matrices generated by Joint VAE models. It analyzes patterns in how input features contribute to predicting output features, constructs importance-based networks, and validates findings against protein-protein interaction (PPI) databases.</p>"},{"location":"feature_importance/#overview","title":"Overview","text":"<p>The feature importance analysis helps answer key questions about the Joint VAE's learned feature relationships: - Which input features are most consistently important across different outputs? - How do self-feature importance patterns relate to actual performance? - What network structures emerge from feature importance relationships? - How well do importance-derived networks align with known biological interactions?</p>"},{"location":"feature_importance/#features","title":"Features","text":""},{"location":"feature_importance/#core-analysis-components","title":"Core Analysis Components","text":"<ol> <li>Rank Consistency Analysis</li> <li>Analyzes how consistently features rank across different prediction targets</li> <li>Identifies features with stable vs. variable importance patterns</li> <li> <p>Generates clustered heatmaps and distribution plots</p> </li> <li> <p>Self-Feature Importance Analysis</p> </li> <li>Examines diagonal elements (self-importance) in importance matrices</li> <li>Compares self-importance vs. cross-importance patterns</li> <li> <p>Correlates self-importance with actual imputation performance</p> </li> <li> <p>Feature Specialization Analysis</p> </li> <li>Determines whether features are specialists (important for few targets) or generalists</li> <li>Uses Gini coefficient to measure importance concentration</li> <li> <p>Visualizes specialization vs. overall importance</p> </li> <li> <p>Network Construction and Analysis</p> </li> <li>Builds networks based on feature importance relationships</li> <li>Two thresholding methods: self-importance ratio and absolute importance</li> <li> <p>Comprehensive network topology analysis including centrality and community detection</p> </li> <li> <p>PPI Validation</p> </li> <li>Compares importance-derived networks with reference PPI databases</li> <li>Identifies novel connections not in PPI and validates known interactions</li> <li> <p>Performs enrichment analysis to assess biological relevance</p> </li> <li> <p>Threshold Optimization</p> </li> <li>Analyzes different threshold values for optimal network construction</li> <li>Provides recommendations based on edge count, density, and biological validation</li> <li>Generates precision-recall curves for PPI validation</li> </ol>"},{"location":"feature_importance/#usage","title":"Usage","text":""},{"location":"feature_importance/#basic-usage","title":"Basic Usage","text":"<pre><code>python scripts/feature_importance_analysis.py \\\n    --importance_a_to_b importance_a_to_b.csv \\\n    --platform_a_name \"Olink\" \\\n    --platform_b_name \"SomaScan\" \\\n    --output_dir importance_analysis_results\n</code></pre>"},{"location":"feature_importance/#with-network-analysis","title":"With Network Analysis","text":"<pre><code>python scripts/feature_importance_analysis.py \\\n    --importance_a_to_b importance_a_to_b.csv \\\n    --importance_b_to_a importance_b_to_a.csv \\\n    --platform_a_name \"Olink\" \\\n    --platform_b_name \"SomaScan\" \\\n    --threshold_method self_importance_ratio \\\n    --threshold_params 10.0 \\\n    --output_dir importance_analysis_results\n</code></pre>"},{"location":"feature_importance/#with-performance-correlation-analysis","title":"With Performance Correlation Analysis","text":"<pre><code>python scripts/feature_importance_analysis.py \\\n    --importance_a_to_b importance_a_to_b.csv \\\n    --importance_b_to_a importance_b_to_a.csv \\\n    --truth_a data/truth_platform_a.csv \\\n    --truth_b data/truth_platform_b.csv \\\n    --imp_a_m1 data/imputed_a_method1.csv \\\n    --imp_b_m1 data/imputed_b_method1.csv \\\n    --platform_a_name \"Olink\" \\\n    --platform_b_name \"SomaScan\" \\\n    --output_dir importance_analysis_results\n</code></pre>"},{"location":"feature_importance/#with-ppi-validation","title":"With PPI Validation","text":"<pre><code>python scripts/feature_importance_analysis.py \\\n    --importance_a_to_b importance_a_to_b.csv \\\n    --importance_b_to_a importance_b_to_a.csv \\\n    --platform_a_name \"Olink\" \\\n    --platform_b_name \"SomaScan\" \\\n    --ppi_reference data/string_ppi.txt \\\n    --ppi_symbol1_col protein1 \\\n    --ppi_symbol2_col protein2 \\\n    --ppi_confidence_col combined_score \\\n    --ppi_confidence_threshold 400 \\\n    --output_dir importance_analysis_results\n</code></pre>"},{"location":"feature_importance/#command-line-arguments","title":"Command Line Arguments","text":""},{"location":"feature_importance/#required-arguments","title":"Required Arguments","text":"<ul> <li><code>--importance_a_to_b</code>: Path to importance matrix CSV (Platform A \u2192 Platform B)</li> <li><code>--platform_a_name</code>: Display name for platform A (e.g., \"Olink\")</li> <li><code>--platform_b_name</code>: Display name for platform B (e.g., \"SomaScan\")</li> </ul>"},{"location":"feature_importance/#optional-data-arguments","title":"Optional Data Arguments","text":"<ul> <li><code>--importance_b_to_a</code>: Path to importance matrix CSV (Platform B \u2192 Platform A)</li> <li><code>--truth_a/--truth_b</code>: Truth data files for performance calculation</li> <li><code>--imp_a_m1/--imp_a_m2</code>: Imputed data files for platform A (methods 1 and 2)</li> <li><code>--imp_b_m1/--imp_b_m2</code>: Imputed data files for platform B (methods 1 and 2)</li> <li><code>--feature_mapping</code>: Feature mapping file (CSV or JSON) for numeric ID \u2192 gene name conversion</li> </ul>"},{"location":"feature_importance/#network-analysis-arguments","title":"Network Analysis Arguments","text":"<ul> <li><code>--threshold_method</code>: Thresholding method (<code>self_importance_ratio</code> or <code>absolute_importance</code>)</li> <li><code>--threshold_params</code>: Threshold parameter value (auto-determined if not provided)</li> <li><code>--network_type</code>: Network type (<code>directed</code> or <code>undirected</code>)</li> <li><code>--target_density</code>: Target network density for recommendations</li> </ul>"},{"location":"feature_importance/#ppi-validation-arguments","title":"PPI Validation Arguments","text":"<ul> <li><code>--ppi_reference</code>: Path to PPI reference file (tab-delimited)</li> <li><code>--ppi_symbol1_col</code>: Column name for first protein symbol (default: \"symbol1\")</li> <li><code>--ppi_symbol2_col</code>: Column name for second protein symbol (default: \"symbol2\")</li> <li><code>--ppi_confidence_col</code>: Column name for confidence scores (optional)</li> <li><code>--ppi_confidence_threshold</code>: Minimum confidence threshold (default: 0.0)</li> </ul>"},{"location":"feature_importance/#output-arguments","title":"Output Arguments","text":"<ul> <li><code>--output_dir</code>: Output directory for results (default: \"importance_matrix_analysis\")</li> </ul>"},{"location":"feature_importance/#input-file-formats","title":"Input File Formats","text":""},{"location":"feature_importance/#importance-matrix-files","title":"Importance Matrix Files","text":"<p>CSV format with input features as rows and output features as columns: <pre><code>Feature,Output1,Output2,Output3,...\nInput1,0.123,0.456,0.789,...\nInput2,0.234,0.567,0.890,...\n</code></pre></p>"},{"location":"feature_importance/#truth-and-imputed-data-files","title":"Truth and Imputed Data Files","text":"<p>CSV format with samples as rows and features as columns: <pre><code>SampleID,Feature1,Feature2,Feature3,...\nSample001,1.23,2.45,0.89,...\nSample002,1.67,2.91,1.12,...\n</code></pre></p>"},{"location":"feature_importance/#feature-mapping-file-optional","title":"Feature Mapping File (Optional)","text":"<p>CSV format mapping numeric IDs to gene names: <pre><code>NumericID,GeneName\n1,APOE\n2,LDLR\n3,PCSK9\n</code></pre></p>"},{"location":"feature_importance/#ppi-reference-file-optional","title":"PPI Reference File (Optional)","text":"<p>Tab-delimited format with protein interaction data: <pre><code>protein1    protein2    combined_score\nAPOE    LDLR    850\nLDLR    PCSK9   650\n</code></pre></p>"},{"location":"feature_importance/#network-construction-methods","title":"Network Construction Methods","text":""},{"location":"feature_importance/#thresholding-methods","title":"Thresholding Methods","text":"<ol> <li>Self-Importance Ratio Method (<code>self_importance_ratio</code>)</li> <li>Logic: Connect if cross-importance &gt; threshold_params \u00d7 self-importance</li> <li>Advantage: Adapts to each feature's self-prediction capability</li> <li>Typical Values: 1.0 - 10.0 (higher = more stringent)</li> <li> <p>Use Case: When features have very different self-importance levels</p> </li> <li> <p>Absolute Importance Method (<code>absolute_importance</code>)</p> </li> <li>Logic: Connect if importance &gt; threshold_params absolute value</li> <li>Advantage: Simple, universal threshold</li> <li>Typical Values: 0.001 - 0.01 (depends on importance scale)</li> <li>Use Case: When importance values are on similar scales</li> </ol>"},{"location":"feature_importance/#automatic-threshold-selection","title":"Automatic Threshold Selection","text":"<p>If no threshold is provided, the script automatically determines optimal values using:</p> <ol> <li>Edge Saturation Method (Primary)</li> <li>Finds threshold where edges \u2264 nodes for meaningful network structure</li> <li> <p>Balances network size with interpretability</p> </li> <li> <p>Target Density Method</p> </li> <li>Aims for user-specified network density (default: 3.66%)</li> <li> <p>Based on biological network density estimates</p> </li> <li> <p>Edge Count Method</p> </li> <li>Targets 1K-10K edges for computational efficiency</li> <li>Balances analysis depth with performance</li> </ol>"},{"location":"feature_importance/#troubleshooting","title":"Troubleshooting","text":""},{"location":"feature_importance/#common-issues","title":"Common Issues","text":"<ol> <li>\"No overlapping features found\"</li> <li>Check that feature names match between importance matrices</li> <li> <p>Verify that matrices have appropriate input/output structure</p> </li> <li> <p>\"NetworkX not available\"</p> </li> <li>Install NetworkX: <code>pip install networkx python-louvain</code></li> <li> <p>Network analysis will be skipped without these packages</p> </li> <li> <p>Memory issues with large matrices</p> </li> <li>Script automatically subsamples for visualization</li> <li> <p>Consider using absolute importance method for very large matrices</p> </li> <li> <p>\"Insufficient data for correlation analysis\"</p> </li> <li>Ensure truth and imputed data files are provided</li> <li>Check that feature names match between files</li> <li> <p>Verify minimum of 3 overlapping features for correlation</p> </li> <li> <p>PPI file loading errors</p> </li> <li>Verify tab-delimited format with correct column names</li> <li>Check protein name format consistency</li> <li>Ensure confidence column contains numerical values</li> </ol>"},{"location":"feature_importance/#performance-optimization","title":"Performance Optimization","text":"<p>For large datasets: - Use <code>absolute_importance</code> method (generally faster than <code>self_importance_ratio</code>) - Provide specific <code>threshold_params</code> to skip threshold analysis - Limit network size by using higher threshold values - Consider running analysis on feature subsets for initial exploration</p>"},{"location":"impute/","title":"Cross-Platform Imputation (<code>impute.py</code>)","text":""},{"location":"impute/#overview","title":"Overview","text":"<p>The <code>impute.py</code> script performs cross-platform imputation using trained cpiVAE models. It loads preprocessing artifacts, applies the trained model to transform data from one platform to another, and optionally computes feature importance using Captum. The script ensures consistent preprocessing between training and inference phases.</p>"},{"location":"impute/#usage","title":"Usage","text":"<pre><code>python scripts/impute.py --experiment_dir EXPERIMENT_DIR --input_data INPUT_FILE --source_platform {a,b} --target_platform {a,b} --output OUTPUT_FILE [OPTIONS]\n</code></pre>"},{"location":"impute/#required-arguments","title":"Required Arguments","text":"<ul> <li><code>--experiment_dir</code>: Path to experiment directory containing model checkpoint and preprocessing artifacts</li> <li><code>--input_data</code>: Path to input CSV/TXT file to be imputed  </li> <li><code>--source_platform</code>: Source platform of input data (<code>a</code> or <code>b</code>)</li> <li><code>--target_platform</code>: Target platform for imputation (<code>a</code> or <code>b</code>, must differ from source)</li> <li><code>--output</code>: Path for output imputed CSV file</li> </ul>"},{"location":"impute/#optional-arguments","title":"Optional Arguments","text":"<ul> <li><code>--checkpoint</code>: Specific checkpoint file to use (auto-detects best checkpoint if not provided)</li> <li><code>--config</code>: Specific config file to use (auto-searches in experiment directory if not provided)</li> <li><code>--output_latent</code>: Path to save latent representations CSV file</li> <li><code>--output_importance</code>: Path to save feature importance matrix CSV file</li> <li><code>--id_column</code>: Name of ID column in input data (auto-detected if not provided)</li> </ul>"},{"location":"impute/#feature-importance-options","title":"Feature Importance Options","text":"<ul> <li><code>--importance_method</code>: Attribution method (<code>integrated_gradients</code>, <code>deeplift</code>, <code>gradient_shap</code>)</li> <li><code>--importance_baseline</code>: Baseline for attribution (<code>zero</code>, <code>mean</code>)</li> <li><code>--importance_steps</code>: Number of steps for integrated gradients (default: 50)</li> </ul>"},{"location":"impute/#input-data-format","title":"Input Data Format","text":""},{"location":"impute/#csvtxt-file-structure","title":"CSV/TXT File Structure","text":"<ul> <li>First column: Sample IDs (must match ID format used during training)</li> <li>Remaining columns: Feature measurements for the source platform</li> <li>Separators: Comma for <code>.csv</code>, tab for <code>.txt</code> files</li> <li>Missing values: Handled automatically during preprocessing</li> </ul>"},{"location":"impute/#example-input","title":"Example Input","text":"<pre><code>SampleID,Protein1,Protein2,Protein3,...\nSample001,1.23,2.45,0.89,...\nSample002,1.67,2.91,1.12,...\n</code></pre>"},{"location":"impute/#preprocessing-pipeline","title":"Preprocessing Pipeline","text":"<p>The script automatically applies the same preprocessing used during training:</p> <ol> <li>Sample Alignment: Matches samples with training data ID format</li> <li>Log Transformation: Applied if configured during training</li> <li>Feature Normalization: Uses saved scalers (z-score, min-max, or robust)</li> <li>Missing Value Handling: Consistent with training preprocessing</li> </ol>"},{"location":"impute/#model-loading-and-inference","title":"Model Loading and Inference","text":""},{"location":"impute/#checkpoint-detection","title":"Checkpoint Detection","text":"<ul> <li>Best checkpoint: Searches for <code>*best*.ckpt</code> files first</li> <li>Last checkpoint: Falls back to <code>last.ckpt</code></li> <li>Latest checkpoint: Uses most recent if others unavailable</li> </ul>"},{"location":"impute/#output-files","title":"Output Files","text":""},{"location":"impute/#imputed-data-output","title":"Imputed Data (<code>--output</code>)","text":"<pre><code>SampleID,ImputedProtein1,ImputedProtein2,...\nSample001,2.31,1.87,...\nSample002,1.94,2.15,...\n</code></pre>"},{"location":"impute/#latent-representations-output_latent","title":"Latent Representations (<code>--output_latent</code>)","text":"<pre><code>SampleID,latent_dim_1,latent_dim_2,...\nSample001,0.45,-0.23,...\nSample002,-0.12,0.67,...\n</code></pre>"},{"location":"impute/#feature-importance-matrix-output_importance","title":"Feature Importance Matrix (<code>--output_importance</code>)","text":"<p>Input features (rows) \u00d7 Output features (columns) importance matrix: <pre><code>,output_feature_0000,output_feature_0001,...\nsource_feature_0,0.0234,0.0156,...\nsource_feature_1,0.0445,0.0289,...\n</code></pre></p>"},{"location":"impute/#examples","title":"Examples","text":""},{"location":"impute/#basic-cross-platform-imputation","title":"Basic Cross-Platform Imputation","text":"<p>Olink to SomaScan: <pre><code>python scripts/impute.py \\\n    --experiment_dir outputs_vae/joint_vae_experiment/version_20250804-120000 \\\n    --input_data data/olink_test.csv \\\n    --source_platform a \\\n    --target_platform b \\\n    --output data/somascan_imputed.csv\n</code></pre></p> <p>SomaScan to Olink: <pre><code>python scripts/impute.py \\\n    --experiment_dir outputs_vae/joint_vae_experiment/version_20250804-120000 \\\n    --input_data data/somascan_test.csv \\\n    --source_platform b \\\n    --target_platform a \\\n    --output data/olink_imputed.csv\n</code></pre></p>"},{"location":"impute/#imputation-with-latent-space-extraction","title":"Imputation with Latent Space Extraction","text":"<pre><code>python scripts/impute.py \\\n    --experiment_dir outputs_vae/joint_vae_experiment/version_20250804-120000 \\\n    --input_data data/olink_test.csv \\\n    --source_platform a \\\n    --target_platform b \\\n    --output data/somascan_imputed.csv \\\n    --output_latent data/olink_latent_vectors.csv\n</code></pre>"},{"location":"impute/#imputation-with-feature-importance-analysis","title":"Imputation with Feature Importance Analysis","text":"<pre><code>python scripts/impute.py \\\n    --experiment_dir outputs_vae/joint_vae_experiment/version_20250804-120000 \\\n    --input_data data/olink_test.csv \\\n    --source_platform a \\\n    --target_platform b \\\n    --output data/somascan_imputed.csv \\\n    --output_importance data/importance_matrix.csv \\\n    --importance_method deeplift\n</code></pre>"},{"location":"impute/#custom-configuration-and-checkpoint","title":"Custom Configuration and Checkpoint","text":"<pre><code>python scripts/impute.py \\\n    --experiment_dir outputs_vae/joint_vae_experiment/version_20250804-120000 \\\n    --config configs/custom_config.yaml \\\n    --checkpoint outputs_vae/joint_vae_experiment/version_20250804-120000/checkpoints/best_model.ckpt \\\n    --input_data data/test_data.csv \\\n    --source_platform a \\\n    --target_platform b \\\n    --output data/imputed_custom.csv\n</code></pre>"},{"location":"impute/#feature-importance-analysis","title":"Feature Importance Analysis","text":""},{"location":"impute/#attribution-methods","title":"Attribution Methods","text":"<p>Integrated Gradients (default): - Computes gradients along straight-line path from baseline to input - Provides stable and theoretically grounded attributions - Suitable for all architectures</p> <p>DeepLift: - Computes importance based on differences from reference baseline - Faster than Integrated Gradients - Good for ReLU-based networks</p> <p>GradientShap: - Combines gradients with Shapley values - Uses input distribution as baseline - Most computationally intensive but theoretically robust</p>"},{"location":"impute/#baseline-selection","title":"Baseline Selection","text":"<p>Zero Baseline (default): - Uses all-zero input as reference point - Suitable when zero represents meaningful \"absence\" of signal</p> <p>Mean Baseline: - Uses sample mean as reference point - Better when zero is not meaningful baseline - Represents \"average\" input sample</p>"},{"location":"impute/#output-format","title":"Output Format","text":"<p>Feature importance generates multiple files: - Importance matrix: Input features \u00d7 Output features importance scores - Global importance: Aggregated importance per input feature - Metadata: Analysis parameters and summary statistics</p>"},{"location":"impute/#error-handling-and-troubleshooting","title":"Error Handling and Troubleshooting","text":""},{"location":"impute/#common-issues","title":"Common Issues","text":"<p>Checkpoint not found: <pre><code># Specify checkpoint explicitly\n--checkpoint path/to/specific/checkpoint.ckpt\n</code></pre></p> <p>Preprocessing artifacts missing: - Ensure experiment directory contains <code>scaler_a.pkl</code>, <code>scaler_b.pkl</code>, <code>feature_names_a.txt</code>, etc. - Re-run training if artifacts are missing</p> <p>Feature count mismatch: - Verify input data has same features as training data - Check platform assignment (a vs b)</p> <p>Memory errors during importance analysis: <pre><code># Use simpler attribution method\n--importance_method deeplift\n\n# Reduce integration steps\n--importance_steps 20\n</code></pre></p>"},{"location":"latent_space/","title":"Latent Space Analysis","text":"<p>The <code>latent_space_analysis.py</code> script provides comprehensive analysis of latent representations learned by cpiVAE for cross-platform proteomics data. It generates detailed visualizations and statistics to understand what biological patterns the model has captured in its latent space.</p>"},{"location":"latent_space/#overview","title":"Overview","text":"<p>The latent space analysis helps answer key questions about the cpiVAE's learned representations: - How well do latent representations align between platforms? - What biological patterns are captured in different latent dimensions? - How can we interpret and validate the learned latent space structure?</p>"},{"location":"latent_space/#usage","title":"Usage","text":""},{"location":"latent_space/#basic-usage","title":"Basic Usage","text":"<pre><code>python scripts/latent_space_analysis.py \\\n    --latent_a data/latent_platform_a.csv \\\n    --latent_b data/latent_platform_b.csv \\\n    --truth_a data/truth_platform_a.csv \\\n    --truth_b data/truth_platform_b.csv \\\n    --platform_a_name \"Olink\" \\\n    --platform_b_name \"SomaScan\" \\\n    --output_dir latent_analysis_results\n</code></pre>"},{"location":"latent_space/#with-biological-groups","title":"With Biological Groups","text":"<pre><code>python scripts/latent_space_analysis.py \\\n    --latent_a data/latent_platform_a.csv \\\n    --latent_b data/latent_platform_b.csv \\\n    --truth_a data/truth_platform_a.csv \\\n    --truth_b data/truth_platform_b.csv \\\n    --groups data/sample_groups.csv \\\n    --platform_a_name \"Olink\" \\\n    --platform_b_name \"SomaScan\" \\\n    --output_dir latent_analysis_results\n</code></pre>"},{"location":"latent_space/#arguments","title":"Arguments","text":""},{"location":"latent_space/#required","title":"Required","text":"<ul> <li><code>--latent_a</code>: Path to latent space CSV file for platform A (samples \u00d7 latent dimensions)</li> <li><code>--latent_b</code>: Path to latent space CSV file for platform B (samples \u00d7 latent dimensions)</li> <li><code>--truth_a</code>: Path to truth data CSV file for platform A (samples \u00d7 features)</li> <li><code>--truth_b</code>: Path to truth data CSV file for platform B (samples \u00d7 features)</li> <li><code>--platform_a_name</code>: Display name for platform A (e.g., \"Olink\")</li> <li><code>--platform_b_name</code>: Display name for platform B (e.g., \"SomaScan\")</li> </ul>"},{"location":"latent_space/#optional","title":"Optional","text":"<ul> <li><code>--groups</code>: Path to biological groups/metadata CSV file (samples \u00d7 group labels)</li> <li><code>--output_dir</code>: Output directory for results (default: <code>latent_analysis_output</code>)</li> <li><code>--transpose_latent</code>: Transpose latent files if dimensions are stored as rows</li> </ul>"},{"location":"latent_space/#input-file-formats","title":"Input File Formats","text":""},{"location":"latent_space/#latent-space-files","title":"Latent Space Files","text":"<p>CSV format with samples as rows and latent dimensions as columns: <pre><code>SampleID,Dim_1,Dim_2,Dim_3,...\nSample001,0.123,-0.456,0.789,...\nSample002,-0.234,0.567,-0.890,...\n</code></pre></p>"},{"location":"latent_space/#truth-data-files","title":"Truth Data Files","text":"<p>CSV format with samples as rows and features as columns: <pre><code>SampleID,Protein1,Protein2,Protein3,...\nSample001,1.23,2.45,0.89,...\nSample002,1.67,2.91,1.12,...\n</code></pre></p>"},{"location":"latent_space/#groups-file-optional","title":"Groups File (Optional)","text":"<p>CSV format with samples as rows and group labels: <pre><code>SampleID,Group\nSample001,Disease\nSample002,Control\nSample003,Disease\n</code></pre></p>"},{"location":"latent_space/#dependencies","title":"Dependencies","text":""},{"location":"latent_space/#required-packages","title":"Required Packages","text":"<ul> <li><code>pandas</code>: Data manipulation</li> <li><code>numpy</code>: Numerical computations</li> <li><code>matplotlib</code>: Plotting</li> <li><code>seaborn</code>: Statistical visualization</li> <li><code>scikit-learn</code>: PCA and t-SNE</li> <li><code>scipy</code>: Statistical functions</li> <li><code>umap-learn</code>: UMAP dimensionality reduction</li> </ul>"},{"location":"latent_space/#troubleshooting","title":"Troubleshooting","text":""},{"location":"latent_space/#common-issues","title":"Common Issues","text":"<ol> <li>\"No common samples found\"</li> <li>Check that sample IDs match between latent files and truth files</li> <li> <p>Verify that files use consistent indexing</p> </li> <li> <p>\"UMAP not available\"</p> </li> <li>Install UMAP: <code>pip install umap-learn</code></li> <li> <p>Analysis will continue with PCA and t-SNE only</p> </li> <li> <p>Memory issues with large datasets</p> </li> <li>The script automatically subsets large matrices for visualization</li> <li> <p>Consider reducing the number of samples for very large datasets</p> </li> <li> <p>Empty or incorrect latent files</p> </li> <li>Verify that latent files contain numerical data</li> <li>Use <code>--transpose_latent</code> if dimensions are stored as rows</li> </ol>"},{"location":"phenotype_association/","title":"Phenotype Association","text":""},{"location":"phenotype_association/#phenotype-association-analysis","title":"Phenotype Association Analysis","text":"<p>This page describes two complementary ways to run phenotype-protein association analyses with covariate adjustment:</p> <ul> <li>Discovery mode over all available phenotypes using <code>scripts/pheno_discovery.py</code></li> <li>Targeted analysis for specified phenotypes integrated into the broader comparison workflow via <code>scripts/compare_result_oneplatform.py</code></li> </ul>"},{"location":"phenotype_association/#discovery-pheno_discoverypy","title":"Discovery: pheno_discovery.py","text":"<p>The discovery script scans all phenotype columns, classifies each as binary or continuous, and performs per-protein association tests using the truth matrix. All tests adjust for the specified age and gender covariates, with the exception that a phenotype does not adjust for itself (gender phenotypes adjust only for age; age phenotypes adjust only for gender). Multiple testing correction is performed using FDR (Benjamini\u2013Hochberg).</p> <p>Usage:</p> <pre><code>python scripts/pheno_discovery.py \\\n  --truth_a PATH/to/truth.csv \\\n  --phenotype_file PATH/to/phenotypes.csv \\\n  --output_dir results_pheno \\\n  --gender_col GENDER --age_col V5AGE52 \\\n  [--transpose]\n</code></pre> <ul> <li>truth_a: Features \u00d7 samples by default (use <code>--transpose</code> if your input is samples \u00d7 features). First column is the index.</li> <li>phenotype_file: Samples as index in the first column; remaining columns are phenotypes.</li> <li>gender_col / age_col: Covariate column names in the phenotype file.</li> </ul> <p>Outputs:</p> <ul> <li>results_pheno/summary_binary_all.csv and summary_continuous_all.csv</li> <li>results_pheno/summary_binary_top5.csv and summary_continuous_top5.csv</li> <li>results_pheno/summary.txt (concise report)</li> <li>Per-phenotype result tables:</li> <li>results_pheno/associations_binary/binary_associations_.csv <li>results_pheno/associations_continuous/continuous_associations_.csv <p>Each per-phenotype table contains effect estimates (odds ratios for binary; beta for continuous), standard errors, p-values, and FDR-adjusted p-values (<code>p_adj</code>).</p>"},{"location":"phenotype_association/#targeted-compare_result_oneplatformpy","title":"Targeted: compare_result_oneplatform.py","text":"<p>The <code>scripts/compare_result_oneplatform.py</code> workflow supports phenotype association analysis for a user-specified set of phenotype columns alongside comprehensive method comparison and figure generation. Provide a phenotype file and explicit phenotype columns via <code>--binary_pheno</code> and <code>--continuous_pheno</code>. The analysis adjusts for age and gender as covariates and will generate per-phenotype result tables and summary figures.</p> <p>Key flags (excerpt):</p> <pre><code>python scripts/compare_result_oneplatform.py \\\n  --truth_a TRUTH_A --imp_a_m1 IMP_A_M1 --imp_a_m2 IMP_A_M2 \\\n  --platform_a_name \"Platform A\" \\\n  --phenotype_file data/phenotypes.csv \\\n  --binary_pheno DIABETES HYPERTENSION \\\n  --continuous_pheno AGE BMI \\\n  [--transpose] \\\n  --output_dir outputs\n</code></pre> <p>Refer to the Comparison documentation for full usage and outputs.</p>"},{"location":"quality_control/","title":"Quality Control","text":""},{"location":"quality_control/#overview","title":"Overview","text":"<p>The cpiVAE framework includes quality control to ensure data integrity and identify potential issues before model training. These tools help detect anomalous samples, assess feature quality, and prepare data for cross-platform analysis.</p>"},{"location":"quality_control/#quality-control-vae-qcpy","title":"Quality Control VAE (<code>qc.py</code>)","text":""},{"location":"quality_control/#overview_1","title":"Overview","text":"<p>The QC VAE script uses a variational autoencoder to detect anomalous samples in proteomics data based on reconstruction error and latent space likelihood. This unsupervised approach identifies outliers without requiring labeled data.</p>"},{"location":"quality_control/#usage","title":"Usage","text":"<pre><code>python scripts/qc.py --data_file DATA_FILE [OPTIONS]\n</code></pre>"},{"location":"quality_control/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>--data_file</code>: Path to CSV/TXT data file for quality control analysis</li> <li><code>--output_dir</code>: Output directory for QC results (default: <code>outputs_qc</code>)</li> <li><code>--config_file</code>: Optional custom configuration file</li> <li><code>--gpu</code>: Use GPU acceleration if available</li> <li><code>--fast_run</code>: Quick debug dev run</li> </ul>"},{"location":"quality_control/#algorithm-details","title":"Algorithm Details","text":"<ol> <li>Data Preprocessing: Log transformation and normalization</li> <li>Model Training: Single-platform VAE with reconstruction and KL losses</li> <li>Anomaly Detection: Samples with high reconstruction error flagged as anomalous</li> <li>Visualization: PCA, UMAP, and latent space plots</li> <li>Reporting: Detailed QC metrics and sample rankings</li> </ol>"},{"location":"quality_control/#configuration-options","title":"Configuration Options","text":"<p>Model Architecture: <pre><code>'model': {\n    'latent_dim': 128,\n    'encoder_layers': [1024],\n    'decoder_layers': [512],\n    'activation': \"leaky_relu\",\n    'dropout_rate': 0.15,\n    'batch_norm': True\n}\n</code></pre></p> <p>Quality Control Parameters: <pre><code>'qc': {\n    'anomaly_threshold_percentile': 80,  # Samples above this percentile flagged\n    'plot_sample_size': 5000,           # Max samples for visualization\n}\n</code></pre></p>"},{"location":"quality_control/#example","title":"Example","text":"<pre><code># Basic QC analysis\npython scripts/qc.py --data_file data/olink_overlap.csv\n\n# Comprehensive QC with custom config\npython scripts/qc.py \\\n    --data_file data/somascan_overlap.csv \\\n    --output_dir outputs_qc_somascan \\\n    --config_file configs/qc_custom.yaml\n</code></pre>"},{"location":"quality_control/#feature-quality-control-qc_featurepy","title":"Feature Quality Control (<code>qc_feature.py</code>)","text":""},{"location":"quality_control/#overview_2","title":"Overview","text":"<p>Feature-level quality control with biological validation, phenotype association analysis, and technical quality assessment. Designed specifically for proteomics data with support for SomaScan and Olink platforms.</p>"},{"location":"quality_control/#usage_1","title":"Usage","text":"<pre><code>python scripts/qc_feature.py --data_file DATA_FILE [OPTIONS]\n</code></pre>"},{"location":"quality_control/#key-parameters_1","title":"Key Parameters","text":"<p>Required: - <code>--data_file</code>: Path to feature data file</p> <p>Optional: - <code>--feature_annot</code>: Feature annotation file with metadata - <code>--sample_pheno</code>: Sample phenotype file for association testing - <code>--categorical_annot</code>: Categorical annotation columns (e.g., QC flags) - <code>--continuous_annot</code>: Continuous annotation columns (e.g., CV values) - <code>--binary_pheno</code>: Binary phenotype columns for association testing - <code>--output_dir</code>: Output directory (default: <code>outputs_feature_qc</code>)</p>"},{"location":"quality_control/#analysis-components","title":"Analysis Components","text":""},{"location":"quality_control/#1-technical-quality-assessment","title":"1. Technical Quality Assessment","text":"<ul> <li>Coefficient of Variation (CV): Measurement precision assessment</li> <li>Missing Value Analysis: Completeness evaluation</li> <li>Dynamic Range: Signal intensity range analysis</li> <li>Batch Effects: Technical variation detection</li> </ul>"},{"location":"quality_control/#2-biological-validation","title":"2. Biological Validation","text":"<ul> <li>Pathway Enrichment: GO term and KEGG pathway analysis (when <code>--run_enrichment</code> specified)</li> <li>Protein-Protein Interactions: Network connectivity analysis (when <code>--run_network</code> specified)</li> <li>Functional Annotation: Biological process categorization</li> </ul>"},{"location":"quality_control/#3-phenotype-association","title":"3. Phenotype Association","text":"<ul> <li>Binary Traits: Association with disease/treatment status</li> <li>Continuous Traits: Correlation with quantitative phenotypes</li> <li>Multiple Testing Correction: FDR and Bonferroni adjustment</li> </ul>"},{"location":"quality_control/#configuration-examples","title":"Configuration Examples","text":""},{"location":"quality_control/#basic-feature-qc","title":"Basic Feature QC","text":"<pre><code>python scripts/qc_feature.py \\\n    --data_file data/olink_overlap.csv \\\n    --output_dir outputs_feature_qc_basic\n</code></pre>"},{"location":"quality_control/#qc-with-annotations","title":"QC with Annotations","text":"<pre><code>python scripts/qc_feature.py \\\n    --data_file data/somascan_overlap.csv \\\n    --feature_annot data/somascan_annotations.txt \\\n    --categorical_annot flag1 flag2 flag3 \\\n    --continuous_annot CV_intra CV_inter \\\n    --output_dir outputs_feature_qc_comprehensive \\\n    --run_biological_analysis \\\n    --run_enrichment \\\n    --run_network\n</code></pre>"},{"location":"train/","title":"Model Training (<code>train.py</code>)","text":""},{"location":"train/#overview","title":"Overview","text":"<p>The <code>train.py</code> script handles the complete training pipeline for cpiVAE models using PyTorch Lightning. It supports multiple model architectures, comprehensive logging, checkpointing, and automatic preprocessing artifact saving for downstream inference.</p>"},{"location":"train/#usage","title":"Usage","text":"<pre><code>python scripts/train.py --config CONFIG_FILE --platform_a PLATFORM_A_FILE --platform_b PLATFORM_B_FILE [OPTIONS]\n</code></pre>"},{"location":"train/#required-arguments","title":"Required Arguments","text":"<ul> <li><code>--config</code>: Path to configuration YAML file (e.g., <code>configs/default.yaml</code>)</li> <li><code>--platform_a</code>: Path to platform A CSV file (training data)</li> <li><code>--platform_b</code>: Path to platform B CSV file (training data)</li> </ul>"},{"location":"train/#optional-arguments","title":"Optional Arguments","text":"<ul> <li><code>--output_dir</code>: Output directory for logs and checkpoints (default: <code>outputs</code>)</li> <li><code>--experiment_name</code>: Name of the experiment (default: <code>joint_vae_experiment</code>)</li> <li><code>--version</code>: Experiment version (default: timestamp <code>version_YYYYMMDD-HHMMSS</code>)</li> <li><code>--resume_from_checkpoint</code>: Path to checkpoint to resume training from</li> <li><code>--fast_dev_run</code>: Run a fast development run for debugging</li> </ul>"},{"location":"train/#supported-model-architectures","title":"Supported Model Architectures","text":""},{"location":"train/#models","title":"Models","text":"<ul> <li><code>joint_vae</code>: jointVAE with dual encoders/decoders (Recommanded)</li> <li><code>joint_vae_plus</code>: Enhanced version with additional tricks</li> <li><code>JointVAEVampPrior</code>: VampPrior variant for improved posterior approximation</li> <li><code>JointIWAE</code>: Importance Weighted Autoencoder variant</li> <li><code>JointVQ</code>: Vector Quantized VAE variant</li> <li><code>JointMM</code>: Mixture Model VAE variant</li> <li><code>res_unet</code>: ResNet-UNet based direct imputation model</li> <li><code>generative_vae</code>: Generative VAE with DDPM or GAN decoder</li> </ul> <p>Note that the base JointVAE performs the best in our testing.</p>"},{"location":"train/#training-pipeline","title":"Training Pipeline","text":""},{"location":"train/#1-data-loading-and-preprocessing","title":"1. Data Loading and Preprocessing","text":"<ul> <li>Loads paired proteomics data from CSV files</li> <li>Automatic feature-wise normalization (z-score, min-max, or robust)</li> <li>Optional log transformation per platform</li> <li>Missing value handling and sample alignment</li> </ul>"},{"location":"train/#2-model-initialization","title":"2. Model Initialization","text":"<ul> <li>Automatic input dimension detection</li> <li>Model architecture selected via configuration</li> <li>Parameter count reporting</li> </ul>"},{"location":"train/#3-training-loop","title":"3. Training Loop","text":"<ul> <li>PyTorch Lightning trainer with GPU/CPU acceleration</li> <li>Gradient clipping and learning rate monitoring</li> <li>Early stopping based on validation metrics</li> <li>Model checkpointing (best and last models)</li> </ul>"},{"location":"train/#4-artifact-saving","title":"4. Artifact Saving","text":"<ul> <li>Preprocessing scalers (<code>scaler_a.pkl</code>, <code>scaler_b.pkl</code>)</li> <li>Feature names (<code>feature_names_a.txt</code>, <code>feature_names_b.txt</code>)</li> <li>Log transformation parameters (<code>log_params.yaml</code>)</li> <li>Configuration backup (<code>config.yaml</code>)</li> </ul>"},{"location":"train/#output-structure","title":"Output Structure","text":"<p>Training creates the following directory structure:</p> <pre><code>{output_dir}/\n\u2514\u2500\u2500 {experiment_name}/\n    \u2514\u2500\u2500 {version}/\n        \u251c\u2500\u2500 checkpoints/\n        \u2502   \u251c\u2500\u2500 {experiment_name}-epoch=XX-val_total_loss=X.XXX.ckpt\n        \u2502   \u2514\u2500\u2500 last.ckpt\n        \u251c\u2500\u2500 config.yaml\n        \u251c\u2500\u2500 scaler_a.pkl\n        \u251c\u2500\u2500 scaler_b.pkl\n        \u251c\u2500\u2500 feature_names_a.txt\n        \u251c\u2500\u2500 feature_names_b.txt\n        \u251c\u2500\u2500 log_params.yaml\n        \u251c\u2500\u2500 final_model.ckpt\n        \u2514\u2500\u2500 tensorboard_logs/\n</code></pre>"},{"location":"train/#configuration-system","title":"Configuration System","text":""},{"location":"train/#model-configuration","title":"Model Configuration","text":"<pre><code>model:\n  model_type: \"joint_vae\"  # Architecture selection\n  latent_dim: 64           # Latent space dimensionality\n  encoder_layers: [512, 256, 128]  # Encoder architecture\n  decoder_layers: [128, 256, 512]  # Decoder architecture\n  dropout_rate: 0.2        # Dropout for regularization\n  activation: \"relu\"       # Activation function\n  batch_norm: true         # Batch normalization\n</code></pre>"},{"location":"train/#training-configuration","title":"Training Configuration","text":"<pre><code>training:\n  max_epochs: 100\n  learning_rate: 0.001\n  batch_size: 64\n  optimizer: \"adam\"\n  gradient_clip_val: 0.5\n  early_stopping_patience: 10\n</code></pre>"},{"location":"train/#hardware-configuration","title":"Hardware Configuration","text":"<pre><code>hardware:\n  accelerator: \"auto\"      # \"auto\", \"gpu\", \"cpu\"\n  devices: \"auto\"          # Device selection\n  precision: 32            # Mixed precision training\n</code></pre>"},{"location":"train/#examples","title":"Examples","text":""},{"location":"train/#basic-training","title":"Basic Training","text":"<pre><code>python scripts/train.py \\\n    --config configs/default.yaml \\\n    --platform_a data/olink_overlap_train.csv \\\n    --platform_b data/somascan_overlap_train.csv\n</code></pre>"},{"location":"train/#custom-experiment","title":"Custom Experiment","text":"<pre><code>python scripts/train.py \\\n    --config configs/default.yaml \\\n    --platform_a data/olink_overlap_train.csv \\\n    --platform_b data/somascan_overlap_train.csv \\\n    --output_dir outputs_custom \\\n    --experiment_name my_joint_vae \\\n    --version v1.0\n</code></pre>"},{"location":"train/#resume-training","title":"Resume Training","text":"<pre><code>python scripts/train.py \\\n    --config configs/default.yaml \\\n    --platform_a data/olink_overlap_train.csv \\\n    --platform_b data/somascan_overlap_train.csv \\\n    --resume_from_checkpoint outputs/joint_vae_experiment/version_20250804-120000/checkpoints/last.ckpt\n</code></pre>"},{"location":"train/#debug-mode","title":"Debug Mode","text":"<pre><code>python scripts/train.py \\\n    --config configs/default.yaml \\\n    --platform_a data/olink_overlap_train.csv \\\n    --platform_b data/somascan_overlap_train.csv \\\n    --fast_dev_run\n</code></pre>"},{"location":"train/#monitoring-and-callbacks","title":"Monitoring and Callbacks","text":""},{"location":"train/#tensorboard-logging","title":"TensorBoard Logging","text":"<p>View training progress: <pre><code>tensorboard --logdir outputs/joint_vae_experiment/version_YYYYMMDD-HHMMSS/\n</code></pre></p> <p>Logged metrics include: - Training/validation losses (total, reconstruction, KL, cross-reconstruction) - Cross-imputation correlations - Learning rate schedules - Model gradients and weights</p>"},{"location":"train/#model-checkpointing","title":"Model Checkpointing","text":"<ul> <li>Best model: Saved based on monitored metric (default: <code>val_total_loss</code>)</li> <li>Last model: Most recent checkpoint</li> <li>Final model: Saved at training completion</li> <li>Configurable via <code>callbacks.model_checkpoint</code> settings</li> </ul>"},{"location":"train/#early-stopping","title":"Early Stopping","text":"<ul> <li>Monitors validation metrics for convergence</li> <li>Configurable patience and minimum delta</li> <li>Prevents overfitting on small datasets</li> </ul>"},{"location":"train/#advanced-features","title":"Advanced Features","text":""},{"location":"train/#multi-gpu-training","title":"Multi-GPU Training","text":"<pre><code>hardware:\n  accelerator: \"gpu\"\n  devices: [0, 1, 2, 3]  # Use specific GPUs\n</code></pre>"},{"location":"train/#mixed-precision-training","title":"Mixed Precision Training","text":"<pre><code>hardware:\n  precision: 16  # Use 16-bit precision for faster training\n</code></pre>"},{"location":"train/#custom-callbacks","title":"Custom Callbacks","text":"<pre><code>callbacks:\n  model_checkpoint:\n    monitor: \"val_cross_a_corr_mean\"\n    mode: \"max\"\n    save_top_k: 5\n  early_stopping:\n    monitor: \"val_cross_a_corr_mean\"\n    mode: \"max\"\n    patience: 15\n</code></pre>"},{"location":"train/#loss-function-components","title":"Loss Function Components","text":"<p>The composite loss function includes:</p> <ol> <li>Reconstruction Loss: Platform-specific data reconstruction</li> <li>KL Divergence: Regularization of latent space</li> <li>Cross-reconstruction Loss: Cross-platform imputation quality</li> <li>Latent Alignment Loss: Shared representation learning</li> </ol> <p>Loss weights are configurable via <code>loss_weights</code> in the config file.</p>"},{"location":"train/#data-format-requirements","title":"Data Format Requirements","text":""},{"location":"train/#input-csv-format","title":"Input CSV Format","text":"<ul> <li>First column: Sample IDs (must match between platforms)</li> <li>Remaining columns: Feature measurements</li> <li>Missing values: Handled automatically during preprocessing</li> </ul>"},{"location":"train/#sample-alignment","title":"Sample Alignment","text":"<ul> <li>Samples are automatically aligned by ID</li> <li>Mismatched samples are excluded with warnings</li> </ul>"},{"location":"train/#performance-optimization","title":"Performance Optimization","text":""},{"location":"train/#memory-management","title":"Memory Management","text":"<ul> <li>Custom and efficient data loading with PyTorch DataLoader</li> <li>Gradient accumulation for large batch simulation</li> </ul>"},{"location":"train/#troubleshooting","title":"Troubleshooting","text":""},{"location":"train/#common-issues","title":"Common Issues","text":"<p>Out of Memory - Reduce batch size in configuration - Use mixed precision training (precision: 16) - Reduce model architecture size</p> <p>Slow Convergence - Increase learning rate - Adjust loss function weights - Check data normalization</p> <p>Poor Cross-imputation Performance - Increase cross-reconstruction loss weight - Adjust latent alignment parameters - Verify data quality and preprocessing</p>"},{"location":"train/#model-selection","title":"Model Selection","text":"<ul> <li>Monitor validation metrics, not training loss</li> <li>Use cross-validation for small datasets</li> <li>Compare multiple model architectures</li> </ul>"},{"location":"tune/","title":"Hyperparameter Tuning (<code>tune.py</code>)","text":""},{"location":"tune/#overview","title":"Overview","text":"<p>The <code>tune.py</code> script performs Bayesian hyperparameter optimization for cpiVAE models using Optuna. It optimizes model parameters based on cross-imputation correlation performance, which is the key metric for evaluating cross-platform proteomics data translation quality.</p>"},{"location":"tune/#usage","title":"Usage","text":"<pre><code>python scripts/tune.py --config CONFIG_FILE --platform_a PLATFORM_A_FILE --platform_b PLATFORM_B_FILE [OPTIONS]\n</code></pre>"},{"location":"tune/#required-arguments","title":"Required Arguments","text":"<ul> <li><code>--config</code>: Path to base configuration YAML file (e.g., <code>configs/default.yaml</code>)</li> <li><code>--platform_a</code>: Path to platform A CSV file (training data)</li> <li><code>--platform_b</code>: Path to platform B CSV file (training data)</li> </ul>"},{"location":"tune/#optional-arguments","title":"Optional Arguments","text":"<ul> <li><code>--output_dir</code>: Output directory for Optuna study and logs (default: <code>outputs_tune</code>)</li> <li><code>--study_name</code>: Name of the Optuna study (default: <code>joint_vae_study</code>)</li> <li><code>--n_trials</code>: Number of optimization trials (default: 50)</li> <li><code>--max_epochs</code>: Maximum epochs per trial (default: 50, reduced for faster tuning)</li> </ul>"},{"location":"tune/#optimization-strategy","title":"Optimization Strategy","text":""},{"location":"tune/#objective-function","title":"Objective Function","text":"<p>The hyperparameter optimizer maximizes the average cross-imputation mean per-feature correlation across both platforms</p>"},{"location":"tune/#hyperparameter-search-space","title":"Hyperparameter Search Space","text":""},{"location":"tune/#model-architecture","title":"Model Architecture","text":"<ul> <li>Learning rate: Log-uniform distribution [1e-5, 1e-2]</li> <li>Latent dimensions: Categorical [16, 32, 64, 128, 256]</li> <li>Dropout rate: Uniform [0.1, 0.5]</li> <li>Activation function: Categorical ['relu', 'leaky_relu', 'gelu', 'swish']</li> <li>Batch normalization: Boolean [True, False]</li> <li>Residual connections: Boolean [True, False]</li> </ul>"},{"location":"tune/#training-parameters","title":"Training Parameters","text":"<ul> <li>Optimizer: Categorical ['adam', 'adamw']</li> <li>Batch size: Categorical [32, 64, 128, 256]</li> <li>Gradient clipping: Uniform [0.5, 2.0]</li> <li>Gaussian noise std: Log-uniform [0.001, 0.5]</li> </ul>"},{"location":"tune/#network-architecture","title":"Network Architecture","text":"<ul> <li>Encoder layers: 1-3 layers, each with size [64, 128, 256, 512, 1024]</li> <li>Decoder layers: 1-3 layers, each with size [64, 128, 256, 512, 1024]</li> </ul>"},{"location":"tune/#loss-function-weights","title":"Loss Function Weights","text":"<ul> <li>Reconstruction weight: Uniform [0.5, 2.0]</li> <li>KL divergence weight: Log-uniform [1e-4, 1e-1]</li> <li>Cross-reconstruction weight: Uniform [0.5, 2.0]</li> <li>Latent alignment weight: Uniform [0.5, 2.0]</li> <li>Alignment type: Categorical ['mse', 'kl_divergence', 'mmd']</li> </ul>"},{"location":"tune/#output-files","title":"Output Files","text":""},{"location":"tune/#study-database","title":"Study Database","text":"<ul> <li><code>{output_dir}/{study_name}.db</code>: SQLite database containing all trial results</li> <li>Allows resuming interrupted studies with <code>load_if_exists=True</code></li> </ul>"},{"location":"tune/#best-configuration","title":"Best Configuration","text":"<ul> <li><code>{output_dir}/{study_name}_best_config.yaml</code>: Optimized configuration file</li> <li>Ready to use with <code>train.py</code> script</li> </ul>"},{"location":"tune/#tensorboard-logs","title":"TensorBoard Logs","text":"<ul> <li><code>{output_dir}/tensorboard_logs/{study_name}/trial_{N}/</code>: Per-trial training logs</li> <li>View with: <code>tensorboard --logdir {output_dir}/tensorboard_logs</code></li> </ul>"},{"location":"tune/#examples","title":"Examples","text":""},{"location":"tune/#basic-tuning","title":"Basic Tuning","text":"<pre><code>python scripts/tune.py \\\n    --config configs/default.yaml \\\n    --platform_a data/olink_overlap_train.csv \\\n    --platform_b data/somascan_overlap_train.csv\n</code></pre>"},{"location":"tune/#extended-tuning-with-custom-parameters","title":"Extended Tuning with Custom Parameters","text":"<pre><code>python scripts/tune.py \\\n    --config configs/default.yaml \\\n    --platform_a data/olink_overlap_train.csv \\\n    --platform_b data/somascan_overlap_train.csv \\\n    --output_dir outputs_extensive_tune \\\n    --study_name extensive_joint_vae_study \\\n    --n_trials 100 \\\n    --max_epochs 30\n</code></pre>"},{"location":"tune/#features","title":"Features","text":""},{"location":"tune/#pruning-strategy","title":"Pruning Strategy","text":"<ul> <li>Uses MedianPruner to terminate unpromising trials early</li> <li>Startup trials: 5</li> <li>Warmup steps: 10</li> <li>Evaluation interval: 5 steps</li> </ul>"},{"location":"tune/#early-stopping","title":"Early Stopping","text":"<ul> <li>Monitors <code>val_cross_a_corr_mean</code> (validation cross-imputation correlation)</li> <li>Mode: maximize correlation</li> <li>Patience: 10 epochs</li> </ul>"},{"location":"tune/#error-handling","title":"Error Handling","text":"<ul> <li>Failed trials return <code>-inf</code> to exclude from optimization</li> <li>Study can be resumed if interrupted</li> <li>Detailed error logging for debugging</li> </ul>"},{"location":"tune/#performance-considerations","title":"Performance Considerations","text":""},{"location":"tune/#computational-requirements","title":"Computational Requirements","text":"<ul> <li>Each trial trains a full model (up to <code>max_epochs</code>)</li> <li>Memory usage scales with batch size and model architecture</li> <li>GPU acceleration recommended for faster trials</li> </ul>"},{"location":"tune/#tuning-strategy","title":"Tuning Strategy","text":"<ul> <li>Start with 50 trials for initial exploration</li> <li>Use shorter <code>max_epochs</code> (30-50) for faster iteration</li> <li>Increase trials (100+) for production hyperparameters</li> </ul>"},{"location":"tune/#study-management","title":"Study Management","text":"<ul> <li>Study results persist in SQLite database</li> <li>Multiple studies can run in parallel with different names</li> <li>Resume interrupted studies automatically</li> </ul>"},{"location":"tune/#best-practices","title":"Best Practices","text":"<ol> <li>Data Preparation: Ensure training data is properly split and preprocessed</li> <li>Configuration Base: Start with a reasonable base configuration</li> <li>Resource Planning: Allocate sufficient GPU memory and time</li> <li>Study Naming: Use descriptive study names for organization</li> <li>Result Analysis: Review TensorBoard logs to understand trial progression</li> </ol>"},{"location":"tune/#study-analysis","title":"Study Analysis","text":"<pre><code>import optuna\n\n# Load and analyze study\nstudy = optuna.load_study(study_name=\"joint_vae_study\", \n                         storage=\"sqlite:///outputs_tune/joint_vae_study.db\")\nprint(f\"Best value: {study.best_value}\")\nprint(f\"Best params: {study.best_params}\")\n\n# Plot optimization history\noptuna.visualization.plot_optimization_history(study)\n</code></pre>"},{"location":"tune/#common-issues","title":"Common Issues","text":"<ul> <li>Out of memory: Reduce <code>max_epochs</code> or trial batch sizes</li> <li>Slow convergence: Increase <code>n_trials</code> or adjust search space</li> <li>Database conflicts: Use unique study names for parallel runs</li> </ul>"}]}